"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–º–µ—Ç–∫–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ MongoDB
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç perceptual hash –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
"""

import os
import imagehash
from dotenv import load_dotenv
import pymongo
from collections import defaultdict
from tqdm import tqdm
from datetime import datetime

load_dotenv()
load_dotenv('mongodb_config.env')

def find_and_mark_duplicates(threshold: int = 5, dry_run: bool = False):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –∏ –ø–æ–º–µ—á–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    Args:
        threshold: –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ Hamming distance (0-10)
                  5 = —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è (–Ω–∞—Ö–æ–¥–∏—Ç –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏)
        dry_run: –ï—Å–ª–∏ True, —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ë–î
    """
    print("üîç –ü–û–ò–°–ö –ò –ü–û–ú–ï–¢–ö–ê –í–ò–ó–£–ê–õ–¨–ù–´–• –î–£–ë–õ–ò–ö–ê–¢–û–í")
    print("="*70)
    print(f"‚öôÔ∏è  Threshold: {threshold} (Hamming distance)")
    print(f"‚öôÔ∏è  Dry run: {'–î–∞ (—Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å)' if dry_run else '–ù–µ—Ç (–ø–æ–º–µ—Ç–∏—Ç—å –≤ –ë–î)'}")
    print("="*70)
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MongoDB
    mongodb_uri = os.getenv('MONGODB_URI', 'mongodb://trend_ai_user:LoGRomE2zJ0k0fuUhoTn@localhost:27017/instagram_gallery')
    client = pymongo.MongoClient(mongodb_uri)
    db = client["instagram_gallery"]
    collection = db["images"]
    
    print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å perceptual hash
    images_with_hash = list(collection.find({
        "image_hash": {"$exists": True, "$ne": None}
    }).sort("parsed_at", 1))  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(images_with_hash)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å perceptual hash")
    
    if len(images_with_hash) == 0:
        print("‚ùå –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å perceptual hash!")
        print("üí° –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python add_perceptual_hash_to_existing.py")
        return
    
    # –ü–æ–∏—Å–∫ –∏ –ø–æ–º–µ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    print("\nüîç –ü–æ–∏—Å–∫ –∏ –ø–æ–º–µ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
    processed_ids = set()
    marked_count = 0
    groups_count = 0
    examples = []  # –•—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–∏–º–µ—Ä–æ–≤
    
    for i, img in enumerate(tqdm(images_with_hash, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")):
        if img["_id"] in processed_ids:
            continue
        
        try:
            current_hash = imagehash.hex_to_hash(img["image_hash"])
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ö–µ—à–∞ –¥–ª—è {img.get('post_id', 'N/A')}: {e}")
            continue
        
        # –ü–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - "–æ—Ä–∏–≥–∏–Ω–∞–ª"
        original = img
        processed_ids.add(img["_id"])
        duplicates_in_group = []
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for j, other_img in enumerate(images_with_hash[i+1:], start=i+1):
            if other_img["_id"] in processed_ids:
                continue
            
            try:
                other_hash = imagehash.hex_to_hash(other_img["image_hash"])
                distance = current_hash - other_hash
                
                if distance <= threshold:
                    # –ù–ê–®–õ–ò –î–£–ë–õ–ò–ö–ê–¢ - —Å—Ä–∞–∑—É –ø–æ–º–µ—á–∞–µ–º –≤ –ë–î!
                    if not dry_run:
                        collection.update_one(
                            {"_id": other_img["_id"]},
                            {
                                "$set": {
                                    "is_duplicate": True,
                                    "duplicate_of": original["_id"],
                                    "duplicate_of_post_id": original.get("post_id"),
                                    "duplicate_hash_distance": int(distance),
                                    "marked_duplicate_at": datetime.now().isoformat()
                                }
                            }
                        )
                    
                    duplicates_in_group.append({
                        "img": other_img,
                        "distance": int(distance)
                    })
                    processed_ids.add(other_img["_id"])
                    marked_count += 1
                    
            except Exception as e:
                continue
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ
        if len(duplicates_in_group) > 0:
            groups_count += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ—Ç—á–µ—Ç–∞
            if len(examples) < 5:
                examples.append({
                    "original": original,
                    "duplicates": duplicates_in_group
                })
    
    print(f"\nüìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {groups_count}")
    print(f"üìä –í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {marked_count}")
    
    if marked_count == 0:
        print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    if len(examples) > 0:
        print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–ø–µ—Ä–≤—ã–µ {len(examples)} –≥—Ä—É–ø–ø):")
        print("-" * 70)
        
        for i, example in enumerate(examples):
            original = example["original"]
            duplicates = example["duplicates"]
            
            print(f"\nüîµ –ì—Ä—É–ø–ø–∞ {i+1}:")
            print(f"   –û–†–ò–ì–ò–ù–ê–õ:")
            print(f"      Post ID: {original.get('post_id', 'N/A')}")
            print(f"      Username: @{original.get('username', 'N/A')}")
            print(f"      Likes: {original.get('likes_count', 0)}")
            print(f"      Hash: {original.get('image_hash', 'N/A')}")
            print(f"   –î–£–ë–õ–ò–ö–ê–¢–´ ({len(duplicates)}):")
            
            for dup_info in duplicates:
                dup = dup_info["img"]
                distance = dup_info["distance"]
                print(f"      ‚Ä¢ Post ID: {dup.get('post_id', 'N/A')}, "
                      f"Username: @{dup.get('username', 'N/A')}, "
                      f"Distance: {distance}")
        
        if groups_count > 5:
            print(f"\n... –∏ –µ—â–µ {groups_count - 5} –≥—Ä—É–ø–ø")
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è is_duplicate
    if not dry_run:
        print("\nüî® –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è is_duplicate...")
        collection.create_index("is_duplicate")
        print("‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω!")
    else:
        print(f"\n‚ö†Ô∏è  DRY RUN MODE: –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ë–î –Ω–µ –≤–Ω–µ—Å–µ–Ω—ã")
        print(f"üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–µ–∑ --dry-run –¥–ª—è –ø–æ–º–µ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    
    print(f"\n{'='*70}")
    print(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {groups_count}")
    print(f"üìä –í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ–º–µ—á–µ–Ω–æ: {marked_count}")
    print(f"{'='*70}")

def unmark_all_duplicates():
    """–°–Ω–∏–º–∞–µ—Ç –ø–æ–º–µ—Ç–∫—É –¥—É–±–ª–∏–∫–∞—Ç–∞ —Å–æ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    print("üîÑ –°–ù–Ø–¢–ò–ï –ü–û–ú–ï–¢–û–ö –î–£–ë–õ–ò–ö–ê–¢–û–í")
    print("="*70)
    
    mongodb_uri = os.getenv('MONGODB_URI', 'mongodb://trend_ai_user:LoGRomE2zJ0k0fuUhoTn@localhost:27017/instagram_gallery')
    client = pymongo.MongoClient(mongodb_uri)
    db = client["instagram_gallery"]
    collection = db["images"]
    
    print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–º–µ—á–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    duplicates_count = collection.count_documents({"is_duplicate": True})
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {duplicates_count} –ø–æ–º–µ—á–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    
    if duplicates_count == 0:
        print("‚úÖ –ù–µ—Ç –ø–æ–º–µ—á–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤!")
        return
    
    # –°–Ω–∏–º–∞–µ–º –ø–æ–º–µ—Ç–∫–∏
    result = collection.update_many(
        {"is_duplicate": True},
        {
            "$set": {"is_duplicate": False},
            "$unset": {
                "duplicate_of": "",
                "duplicate_of_post_id": "",
                "duplicate_hash_distance": "",
                "marked_duplicate_at": ""
            }
        }
    )
    
    print(f"‚úÖ –°–Ω—è—Ç–æ –ø–æ–º–µ—Ç–æ–∫: {result.modified_count}")
    print("="*70)

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="–ü–æ–∏—Å–∫ –∏ –ø–æ–º–µ—Ç–∫–∞ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    parser.add_argument("--threshold", type=int, default=5, 
                       help="–ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ Hamming distance (0-10, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5)")
    parser.add_argument("--dry-run", action="store_true",
                       help="–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ë–î")
    parser.add_argument("--unmark", action="store_true",
                       help="–°–Ω—è—Ç—å –ø–æ–º–µ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–æ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    args = parser.parse_args()
    
    if args.unmark:
        unmark_all_duplicates()
    else:
        find_and_mark_duplicates(threshold=args.threshold, dry_run=args.dry_run)

