"""
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URL —Å—Ç–∞—Ç–∏—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –¥–∞–Ω–Ω—ã—Ö Instagram
"""

import os
import json
import pandas as pd
from datetime import datetime

def extract_image_urls():
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –¥–∞–Ω–Ω—ã—Ö Instagram"""
    
    print("üñºÔ∏è –ò–ó–í–õ–ï–ß–ï–ù–ò–ï URL –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô –ò–ó –î–ê–ù–ù–´–• INSTAGRAM")
    print("="*60)
    
    # –ò—â–µ–º JSON —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏
    import glob
    json_files = glob.glob("image_urls_*.json")
    
    if not json_files:
        print("‚ùå JSON —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return None
    
    # –ë–µ—Ä–µ–º —Å–∞–º—ã–π –Ω–æ–≤—ã–π —Ñ–∞–π–ª
    latest_file = max(json_files)
    print(f"üìÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª: {latest_file}")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –ø–æ—Å—Ç–æ–≤")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —É–¥–∞–ª–µ–Ω–∏–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        image_urls = []
        seen_urls = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö URL
        
        for i, post in enumerate(data):
            if isinstance(post, dict):
                post_info = {
                    'post_index': i + 1,
                    'shortCode': post.get('shortCode', 'N/A'),
                    'url': post.get('url', 'N/A'),
                    'type': post.get('type', 'N/A'),
                    'timestamp': post.get('timestamp', 'N/A'),
                    'likesCount': post.get('likesCount', 0),
                    'commentsCount': post.get('commentsCount', 0),
                    'caption': post.get('caption', '')[:100] + '...' if post.get('caption') else 'N/A'
                }
                
                # –û—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (displayUrl)
                if post.get('displayUrl'):
                    url = post['displayUrl']
                    if url not in seen_urls:
                        seen_urls.add(url)
                        image_info = post_info.copy()
                        image_info['image_url'] = url
                        image_info['image_type'] = 'main'
                        image_urls.append(image_info)
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (images array)
                if post.get('images'):
                    for j, img_url in enumerate(post['images']):
                        if isinstance(img_url, str) and img_url not in seen_urls:
                            seen_urls.add(img_url)
                            image_info = post_info.copy()
                            image_info['image_url'] = img_url
                            image_info['image_type'] = f'gallery_{j+1}'
                            image_urls.append(image_info)
                
                # Child posts (–¥–ª—è Sidecar –ø–æ—Å—Ç–æ–≤)
                if post.get('childPosts'):
                    for j, child_post in enumerate(post['childPosts']):
                        if isinstance(child_post, dict):
                            if child_post.get('displayUrl'):
                                url = child_post['displayUrl']
                                if url not in seen_urls:
                                    seen_urls.add(url)
                                    image_info = post_info.copy()
                                    image_info['image_url'] = url
                                    image_info['image_type'] = f'child_{j+1}'
                                    image_urls.append(image_info)
                            
                            if child_post.get('images'):
                                for k, img_url in enumerate(child_post['images']):
                                    if isinstance(img_url, str) and img_url not in seen_urls:
                                        seen_urls.add(img_url)
                                        image_info = post_info.copy()
                                        image_info['image_url'] = img_url
                                        image_info['image_type'] = f'child_{j+1}_gallery_{k+1}'
                                        image_urls.append(image_info)
        
        print(f"üñºÔ∏è –ù–∞–π–¥–µ–Ω–æ {len(image_urls)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        print(f"üîÑ –î—É–±–ª–∏–∫–∞—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª–µ–Ω—ã")
        
        if image_urls:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ URL
            print(f"\nüìã –ü–ï–†–í–´–ï 10 URL –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:")
            print("="*50)
            
            for i, img in enumerate(image_urls[:10]):
                print(f"\n{i+1}. üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:")
                print(f"   üîó URL: {img['image_url']}")
                print(f"   üìù –¢–∏–ø: {img['image_type']}")
                print(f"   üì∏ –ü–æ—Å—Ç: {img['shortCode']}")
                print(f"   ‚ù§Ô∏è –õ–∞–π–∫–∏: {img['likesCount']}")
                print(f"   üìÖ –î–∞—Ç–∞: {img['timestamp']}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # JSON —Ñ–∞–π–ª
            json_filename = f"image_urls_{timestamp}.json"
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(image_urls, f, ensure_ascii=False, indent=2)
            print(f"\nüíæ JSON —Å URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {json_filename}")
            
            # CSV —Ñ–∞–π–ª
            df = pd.DataFrame(image_urls)
            csv_filename = f"image_urls_{timestamp}.csv"
            df.to_csv(csv_filename, index=False, encoding='utf-8')
            print(f"üíæ CSV —Å URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {csv_filename}")
            
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ —Å URL
            txt_filename = f"image_urls_only_{timestamp}.txt"
            with open(txt_filename, 'w', encoding='utf-8') as f:
                for img in image_urls:
                    f.write(f"{img['image_url']}\n")
            print(f"üíæ –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å URL —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {txt_filename}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:")
            print("="*35)
            print(f"üìà –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_urls)}")
            print(f"üîÑ –î—É–±–ª–∏–∫–∞—Ç—ã —É–¥–∞–ª–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            
            # –¢–∏–ø—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            image_types = {}
            for img in image_urls:
                img_type = img['image_type']
                image_types[img_type] = image_types.get(img_type, 0) + 1
            
            print(f"\nüìù –¢–∏–ø—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
            for img_type, count in sorted(image_types.items()):
                print(f"   {img_type}: {count}")
            
            # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–æ–º–µ–Ω—ã
            domains = set()
            for img in image_urls:
                try:
                    from urllib.parse import urlparse
                    domain = urlparse(img['image_url']).netloc
                    domains.add(domain)
                except:
                    pass
            
            print(f"\nüåê –î–æ–º–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
            for domain in sorted(domains):
                print(f"   {domain}")
            
            # –¢–æ–ø –ø–æ—Å—Ç–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            post_image_counts = {}
            for img in image_urls:
                post_code = img['shortCode']
                post_image_counts[post_code] = post_image_counts.get(post_code, 0) + 1
            
            top_posts = sorted(post_image_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            print(f"\nüì∏ –¢–æ–ø-5 –ø–æ—Å—Ç–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
            for post_code, count in top_posts:
                print(f"   {post_code}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        return image_urls
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return None

def download_images_sample(image_urls, max_images=5):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞"""
    
    print(f"\n‚¨áÔ∏è –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ü–†–ò–ú–ï–†–û–í –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô")
    print("="*40)
    
    try:
        import requests
        from urllib.parse import urlparse
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        os.makedirs('sample_images', exist_ok=True)
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        for i, img in enumerate(image_urls[:max_images]):
            try:
                url = img['image_url']
                response = requests.get(url, timeout=10)
                
                if response.status_code == 200:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                    parsed_url = urlparse(url)
                    filename = f"sample_images/image_{i+1}_{img['shortCode']}.jpg"
                    
                    with open(filename, 'wb') as f:
                        f.write(response.content)
                    
                    print(f"‚úÖ –°–∫–∞—á–∞–Ω–æ: {filename}")
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {url}: {response.status_code}")
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {i+1}: {e}")
        
        print(f"\nüíæ –ü—Ä–∏–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É: sample_images/")
        
    except ImportError:
        print("‚ö†Ô∏è –î–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ requests: pip install requests")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")

if __name__ == "__main__":
    # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_urls = extract_image_urls()
    
    if image_urls:
        print(f"\nüéâ –£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(image_urls)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")
        print(f"üîÑ –î—É–±–ª–∏–∫–∞—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª–µ–Ω—ã")
        
        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º —Å–∫–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã
        print(f"\nüí° –•–æ—Ç–∏—Ç–µ —Å–∫–∞—á–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π? (y/n)")
        # –î–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∂–∏–º–∞ —Å–∫–∞—á–∏–≤–∞–µ–º 3 –ø—Ä–∏–º–µ—Ä–∞
        download_images_sample(image_urls, max_images=3)
        
        print(f"\nüìã –¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å:")
        print(f"   ‚Ä¢ JSON —Ñ–∞–π–ª —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö")
        print(f"   ‚Ä¢ CSV —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)")
        print(f"   ‚Ä¢ –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ URL")
        print(f"   ‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã —Å–∫–∞—á–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    else:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
